---
title: "Baseball Data - Data Exploration and Preparation"
author: "Mary Anna Kivenson"
date: "February 15, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(corrplot)
library(psych)
library(ggplot2)
require(gridExtra)
library(car)
library(mice)
library(VIM)
library(caret)
library(dplyr)
library(MASS)
```

# Data Exploration

#### Read Data

Here, we read the dataset and shorten the feature names for better readibility in visualizations.

```{r}
df <- read.csv("https://raw.githubusercontent.com/mkivenson/Business-Analytics-Data-Mining/master/Moneyball%20Regression/moneyball-training-data.csv")[-1]
names(df) <- sub("TEAM_", "", names(df))
names(df) <- sub("BATTING_", "bt_", names(df))
names(df) <- sub("BASERUN_", "br_", names(df))
names(df) <- sub("FIELDING_", "fd_", names(df))
names(df) <- sub("PITCHING_", "ph_", names(df))
names(df) <- sub("TARGET_", "", names(df))
head(df)
```

#### Summary

First, we take a look at a summary of the data. A few things of interest are revealed:

* bt_SO, br_SB, br_CS, bt_HBP, ph_SO, and fd_DP have missing values
* The max values of ph_H, ph_BB, ph_SO, and fd_E seem abnormally high

```{r}
summary(df)
```

#### Histogram

Next, we create histograms of each of the features and target variable. 

* bt_H, bt_2B, bt_BB, br_CS, bt_HBP, fd_DP, WINS all have normal distributions
* ph_H, ph_BB, ph_SO, and fd_E are highly right-skewed

```{r warning=FALSE}
grid.arrange(ggplot(df, aes(bt_H)) + geom_histogram(binwidth = 30),
             ggplot(df, aes(bt_2B)) + geom_histogram(binwidth = 10),
             ggplot(df, aes(bt_3B)) + geom_histogram(binwidth = 10),
             ggplot(df, aes(bt_HR)) + geom_histogram(binwidth = 10),
             ggplot(df, aes(bt_BB)) + geom_histogram(binwidth = 30),
             ggplot(df, aes(bt_SO)) + geom_histogram(binwidth = 50),
             ggplot(df, aes(br_SB)) + geom_histogram(binwidth = 30),
             ggplot(df, aes(br_CS)) + geom_histogram(binwidth = 10),
             ggplot(df, aes(bt_HBP)) + geom_histogram(binwidth = 3),
             ggplot(df, aes(ph_H)) + geom_histogram(binwidth = 100),
             ggplot(df, aes(ph_HR)) + geom_histogram(binwidth = 10),
             ggplot(df, aes(ph_BB)) + geom_histogram(binwidth = 100),
             ggplot(df, aes(ph_SO)) + geom_histogram(binwidth = 30),
             ggplot(df, aes(fd_E)) + geom_histogram(binwidth = 30),
             ggplot(df, aes(fd_DP)) + geom_histogram(binwidth = 10),
             ggplot(df, aes(WINS)) + geom_histogram(binwidth = 5),
             ncol=4)
```


#### QQ Plots

* Most of the features are not lined up with the theoretical QQ plot, however this will be addressed by the models we build.

```{r echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow=c(4,4), cex=.8, mai=c(0,0,0.2,0))
invisible(qqPlot(~ bt_H, data = df, main = "bt_H"))
invisible(qqPlot(~ bt_2B, data = df, main = "bt_2B"))
invisible(qqPlot(~ bt_3B, data = df, main = "bt_3B"))
invisible(qqPlot(~ bt_HR, data = df, main = "bt_HR"))
invisible(qqPlot(~ bt_BB, data = df, main = "bt_BB"))
invisible(qqPlot(~ bt_SO, data = df, main = "bt_SO"))
invisible(qqPlot(~ br_SB, data = df, main = "br_SB"))
invisible(qqPlot(~ br_CS, data = df, main = "br_CS"))
invisible(qqPlot(~ bt_HBP, data = df, main = "bt_HBP"))
invisible(qqPlot(~ ph_H, data = df, main = "ph_H"))
invisible(qqPlot(~ ph_HR, data = df, main = "ph_HR"))
invisible(qqPlot(~ ph_BB, data = df, main = "ph_BB"))
invisible(qqPlot(~ ph_SO, data = df, main = "ph_SO"))
invisible(qqPlot(~ fd_E, data = df, main = "fd_E"))
invisible(qqPlot(~ fd_DP, data = df, main = "fd_DP"))
invisible(qqPlot(~ WINS, data = df, main = "WINS"))
```



#### Boxplot

* Most of the boxplots shown below reflect a long right tail with many outliers.

```{r warning=FALSE}
grid.arrange(ggplot(df, aes(x = "bt_H", y = bt_H))+geom_boxplot(),
             ggplot(df, aes(x = "bt_2B", y = bt_2B))+geom_boxplot(),
             ggplot(df, aes(x = "bt_3B", y = bt_3B))+geom_boxplot(),
             ggplot(df, aes(x = "bt_HR", y = bt_HR))+geom_boxplot(),
             ggplot(df, aes(x = "bt_BB", y = bt_BB))+geom_boxplot(),
             ggplot(df, aes(x = "bt_SO", y = bt_SO))+geom_boxplot(),
             ggplot(df, aes(x = "br_SB", y = br_SB))+geom_boxplot(),
             ggplot(df, aes(x = "br_CS", y = br_CS))+geom_boxplot(),
             ggplot(df, aes(x = "bt_HBP", y = bt_HBP))+geom_boxplot(),
             ggplot(df, aes(x = "ph_H", y = ph_H))+geom_boxplot(),
             ggplot(df, aes(x = "ph_HR", y = ph_HR))+geom_boxplot(),
             ggplot(df, aes(x = "ph_BB", y = ph_BB))+geom_boxplot(),
             ggplot(df, aes(x = "ph_SO", y = ph_SO))+geom_boxplot(),
             ggplot(df, aes(x = "fd_E", y = fd_E))+geom_boxplot(),
             ggplot(df, aes(x = "fd_DP", y = fd_DP))+geom_boxplot(),
             ggplot(df, aes(x = "WINS", y = WINS))+geom_boxplot(),
             ncol=4)
```




#### Correlation Plot

* There is a strong positive correlation between ph_H and bt_H
* There is a strong positive correlation between ph_HR and bt_HR
* There is a strong positive correlation between ph_BB and bt_BB
* There is a strong positive correlation between ph_SO and bt_SO
* There seems to be a weak correlation between bt_HBP/br_SB and Wins

```{r}
corrplot(cor(df, use = "complete.obs"), method="color", type="lower", tl.col = "black", tl.srt = 25)
```




#### Scatter Plots

Here, we see a scatter plot of each of the feature variables with the target variable. 

```{r warning=FALSE}
grid.arrange(ggplot(df, aes(bt_H, WINS)) + geom_point(),
             ggplot(df, aes(bt_2B, WINS)) + geom_point(),
             ggplot(df, aes(bt_3B, WINS)) + geom_point(),
             ggplot(df, aes(bt_HR, WINS)) + geom_point(),
             ggplot(df, aes(bt_BB, WINS)) + geom_point(),
             ggplot(df, aes(bt_SO, WINS)) + geom_point(),
             ggplot(df, aes(br_SB, WINS)) + geom_point(),
             ggplot(df, aes(br_CS, WINS)) + geom_point(),
             ggplot(df, aes(bt_HBP, WINS)) + geom_point(),
             ggplot(df, aes(ph_H, WINS)) + geom_point(),
             ggplot(df, aes(ph_HR, WINS)) + geom_point(),
             ggplot(df, aes(ph_BB, WINS)) + geom_point(),
             ggplot(df, aes(ph_SO, WINS)) + geom_point(),
             ggplot(df, aes(fd_E, WINS)) + geom_point(),
             ggplot(df, aes(fd_DP, WINS)) + geom_point(),
             ncol=4)
```

# Data Preparation


### Outliers


#### Extreme Values

While exploring the data, we noticed that the max values of ph_H, ph_BB, ph_SO, and fd_E seem abnormally high.

We see that the record for most hits in a season by team (ph_H) was set at 1,724 in 1921. However, we also know that the datapoints were normalized for 162 games in a season. To take a moderate approach, we will remove the some of the most egggregious outliers that are seen in these variables.

```{r message=FALSE, warning=FALSE}
grid.arrange(ggplot(df, aes(x = "ph_H", y = ph_H))+geom_boxplot(),
             ggplot(df, aes(x = "ph_BB", y = ph_BB))+geom_boxplot(),
             ggplot(df, aes(x = "ph_SO", y = ph_SO))+geom_boxplot(),
             ggplot(df, aes(x = "fd_E", y = fd_E))+geom_boxplot(),
             ncol=4)


df <- filter(df, ph_H < 15000 | ph_BB < 1500 | ph_SO < 3000 | fd_E < 1500)
```


#### Cooks Distance

We will also remove influencial outliers using Cooks distance. 

```{r}
mod <- lm(WINS ~ ., data=df)
cooksd <- cooks.distance(mod)
plot(cooksd, pch="*", cex=2, main="Influential Outliers by Cooks distance")
abline(h = 4*mean(cooksd, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")  # add labels
```


We remove the influencial outliers.

```{r}
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])
df <- df[-influential, ]
```

### Fill Missing Values

The following features have missing values.

* bt_SO - Strikeouts by batters
* br_SB - Stolen bases 
* br_CS - Caught stealing 
* bt_HBP - Batters hit by pitch (get a free base) 
* ph_SO - Strikeouts by pitchers
* fd_DP - Double Plays

Since most values in bt_HBP are missing (90%), we will drop this feature.


#### Multivariate Imputation by Chained Equations (mice)

We will use Multivariable Imputation by Chained Equations (mice) to fill the missing variables.

```{r}
df <- subset(df, select = -c(bt_HBP))
aggr_plot <- aggr(df, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(data), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
```

```{r message=FALSE, warning=FALSE, include=FALSE}
tempData <- mice(df,m=5,maxit=50,meth='pmm',seed=500)
df <- complete(tempData,1)
```


### Address Correlated Features

While exploring the data, we noticed several features had strong positive linear relationships.

Let's run a Variance Inflation Factor test to detect multicollinearity. Features with a VIF score > 10 will be reviewed. 

```{r}
model1 <- lm(WINS ~., data = df)
car::vif(model1)
```


Let's make another correlation plot with only these features.

* bt_SO (strikeouts by batters) and bt_H (base hits by batters) have a strong positive correlation
* bt_H (base hits by batters) and bt_BB (walks by batters) have a strong positive correlation
* ph_BB (walks allowed) and bt_BB (walks by batters) have a strong negative correlation 
* ph_SO (strikeouts by pitchers) and bt_SO (strikeouts by batters) have a moderate negative correlation
* ph_HR (homeruns allowed) and bt_HR (homeruns by batters) have a strong negative correlation
* ph_SO (strikeouts by pitchers) and ph_BB (walks allowed) have a moderate negative correation

```{r}
corrplot(cor(subset(df, select = c(WINS, bt_H, bt_HR, bt_BB, bt_SO, ph_H, ph_HR, ph_BB, ph_SO)), use = "complete.obs"), method="color", type="lower", tl.col = "black", tl.srt = 25)
```


To fix this, we can remove some correlated features and combine others. 

* Remove bt_HR. It has an extremely strong correlation with ph_HR.
* Remove bt_SO. It has an extremely strong correlation with ph_SO.
* Replace bt_H (total base hits by batters) with BT_1B = bt_H - BT_2B - BT_3B - BT_HR (1B base hits)
* Replace ph_BB and bt_BB as a ratio of walks by batters to walks allowed


```{r}
df$bt_1B <- df$bt_H - df$bt_2B - df$bt_3B - df$bt_HR
df$BB <- df$bt_BB / df$ph_BB
df2 <- subset(df, select = -c(bt_HR, bt_SO, bt_H, bt_BB, ph_BB))
```

These adjustments result in less multicollinearity.


```{r}
model1 <- lm(WINS ~., data = df2)
car::vif(model1)
```


### Create Output

```{r}
write.csv(df, "C:\\Users\\mkive\\Documents\\GitHub\\Business-Analytics-Data-Mining\\Business-Analytics-Data-Mining\\Moneyball Regression\\baseball_output.csv")
```

```{r}
df_eval <- read.csv("https://raw.githubusercontent.com/mkivenson/Business-Analytics-Data-Mining/master/Moneyball%20Regression/moneyball-evaluation-data.csv")[-1]
df_eval
```

